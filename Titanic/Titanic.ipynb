{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass                                               Name  \\\n",
      "PassengerId                                                              \n",
      "1                 3                            Braund, Mr. Owen Harris   \n",
      "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "3                 3                             Heikkinen, Miss. Laina   \n",
      "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "5                 3                           Allen, Mr. William Henry   \n",
      "\n",
      "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
      "PassengerId                                                                \n",
      "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
      "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
      "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
      "4            female  35.0      1      0            113803  53.1000  C123   \n",
      "5              male  35.0      0      0            373450   8.0500   NaN   \n",
      "\n",
      "            Embarked  \n",
      "PassengerId           \n",
      "1                  S  \n",
      "2                  C  \n",
      "3                  S  \n",
      "4                  S  \n",
      "5                  S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "\n",
    "y = train[\"Survived\"] #Answer vector\n",
    "train = train.drop([\"Survived\"], 1) #Don't want to train with this\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miss.', 'Rev.', 'NaN', 'Mrs.', 'Col.', 'Ms.', 'Mr.', 'Dr.', 'Master.']\n",
      "             Pclass   Name     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
      "PassengerId                                                                   \n",
      "1                 3    Mr.    male  22.0      1      0   7.2500   NaN        S\n",
      "2                 1   Mrs.  female  38.0      1      0  71.2833     C        C\n",
      "3                 3  Miss.  female  26.0      0      0   7.9250   NaN        S\n",
      "4                 1   Mrs.  female  35.0      1      0  53.1000     C        S\n",
      "5                 3    Mr.    male  35.0      0      0   8.0500   NaN        S\n"
     ]
    }
   ],
   "source": [
    "def process_name(name):\n",
    "    temp_name = name.split(',')[1].split()[0]\n",
    "    if temp_name in ['Miss.', 'Rev.', 'Dona.', 'Mrs.', 'Col.', 'Ms.', 'Mr.', 'Dr.', 'Master.']:\n",
    "        return temp_name\n",
    "    return \"NaN\"\n",
    "    #return name.split(',')[1].split()[0] # Just the prefix, Mr. Mrs. etc.\n",
    "\n",
    "def process_cabin(cabin):\n",
    "    if type(cabin) is float:\n",
    "        return cabin\n",
    "    return cabin[0] #We only want the letter, numbers don't matter\n",
    "train = train.drop(\"Ticket\", 1) # There's no method to the madness there, impossible to parse\n",
    "\n",
    "train[\"Name\"] = train[\"Name\"].apply(process_name)\n",
    "train[\"Cabin\"] = train[\"Cabin\"].apply(process_cabin)\n",
    "\n",
    "print list(set(list(train[\"Name\"]))) #Verify all the different names that pop up\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass  Sex   Age  SibSp  Parch     Fare  Name_Col.  Name_Dr.  \\\n",
      "PassengerId                                                                  \n",
      "1                 3    1  22.0      1      0   7.2500        0.0       0.0   \n",
      "2                 1    0  38.0      1      0  71.2833        0.0       0.0   \n",
      "3                 3    0  26.0      0      0   7.9250        0.0       0.0   \n",
      "4                 1    0  35.0      1      0  53.1000        0.0       0.0   \n",
      "5                 3    1  35.0      0      0   8.0500        0.0       0.0   \n",
      "\n",
      "             Name_Master.  Name_Miss.     ...      Cabin_B  Cabin_C  Cabin_D  \\\n",
      "PassengerId                               ...                                  \n",
      "1                     0.0         0.0     ...          0.0      0.0      0.0   \n",
      "2                     0.0         0.0     ...          0.0      1.0      0.0   \n",
      "3                     0.0         1.0     ...          0.0      0.0      0.0   \n",
      "4                     0.0         0.0     ...          0.0      1.0      0.0   \n",
      "5                     0.0         0.0     ...          0.0      0.0      0.0   \n",
      "\n",
      "             Cabin_E  Cabin_F  Cabin_G  Cabin_T  Embarked_C  Embarked_Q  \\\n",
      "PassengerId                                                               \n",
      "1                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "2                0.0      0.0      0.0      0.0         1.0         0.0   \n",
      "3                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "4                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "5                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "\n",
      "             Embarked_S  \n",
      "PassengerId              \n",
      "1                   1.0  \n",
      "2                   0.0  \n",
      "3                   1.0  \n",
      "4                   1.0  \n",
      "5                   1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Next step is converting everything that isn't NaN to an integer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sex_le = LabelEncoder()\n",
    "train[\"Sex\"] = sex_le.fit_transform(train[\"Sex\"].values) #This works good for something binary, but not cabin/embarked\n",
    "\n",
    "cols_to_transform = [\"Name\", \"Cabin\", \"Embarked\"]\n",
    "train = pd.get_dummies(train, prefix=cols_to_transform)\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.     1.    22.     1.     0.     7.25   0.     0.     0.     0.     1.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.  ]\n",
      "   Pclass  Sex   Age  SibSp  Parch     Fare  Name_Col.  Name_Dr.  \\\n",
      "0     3.0  1.0  22.0    1.0    0.0   7.2500        0.0       0.0   \n",
      "1     1.0  0.0  38.0    1.0    0.0  71.2833        0.0       0.0   \n",
      "2     3.0  0.0  26.0    0.0    0.0   7.9250        0.0       0.0   \n",
      "3     1.0  0.0  35.0    1.0    0.0  53.1000        0.0       0.0   \n",
      "4     3.0  1.0  35.0    0.0    0.0   8.0500        0.0       0.0   \n",
      "\n",
      "   Name_Master.  Name_Miss.     ...      Cabin_A  Cabin_B  Cabin_C  Cabin_D  \\\n",
      "0           0.0         0.0     ...          0.0      0.0      0.0      0.0   \n",
      "1           0.0         0.0     ...          0.0      0.0      1.0      0.0   \n",
      "2           0.0         1.0     ...          0.0      0.0      0.0      0.0   \n",
      "3           0.0         0.0     ...          0.0      0.0      1.0      0.0   \n",
      "4           0.0         0.0     ...          0.0      0.0      0.0      0.0   \n",
      "\n",
      "   Cabin_E  Cabin_F  Cabin_G  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "1      0.0      0.0      0.0         1.0         0.0         0.0  \n",
      "2      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "4      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Index([u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Name_Col.',\n",
      "       u'Name_Dr.', u'Name_Master.', u'Name_Miss.', u'Name_Mr.', u'Name_Mrs.',\n",
      "       u'Name_Ms.', u'Name_Rev.', u'Cabin_A', u'Cabin_B', u'Cabin_C',\n",
      "       u'Cabin_D', u'Cabin_E', u'Cabin_F', u'Cabin_G', u'Embarked_C',\n",
      "       u'Embarked_Q', u'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Next we remove everything that is NaN\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values=\"NaN\", strategy=\"mean\", axis=0)\n",
    "\n",
    "col_names = train.columns #Array of the column headers\n",
    "\n",
    "imr.fit(train)\n",
    "imputed_train = imr.transform(train.values)\n",
    "print imputed_train[0]\n",
    "train = pd.DataFrame(imputed_train)\n",
    "train.columns = col_names\n",
    "train = train.drop([\"Name_NaN\", \"Cabin_T\"], 1) # Not in the test dataset\n",
    "print train.head()\n",
    "print train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex       Age  SibSp  Parch      Fare  Name_Col.  Name_Dr.  \\\n",
      "813     3.0  0.0 -1.823750    4.0    2.0 -0.018709        0.0       0.0   \n",
      "208     3.0  0.0 -1.054207    0.0    0.0 -0.492378        0.0       0.0   \n",
      "444     3.0  1.0  0.000000    0.0    0.0 -0.485079        0.0       0.0   \n",
      "259     2.0  0.0  1.562241    0.0    1.0 -0.124920        0.0       0.0   \n",
      "597     3.0  1.0  1.485287    0.0    0.0 -0.648422        0.0       0.0   \n",
      "\n",
      "     Name_Master.  Name_Miss.     ...      Cabin_A  Cabin_B  Cabin_C  Cabin_D  \\\n",
      "813           0.0         1.0     ...          0.0      0.0      0.0      0.0   \n",
      "208           0.0         1.0     ...          0.0      0.0      0.0      0.0   \n",
      "444           0.0         0.0     ...          0.0      0.0      0.0      0.0   \n",
      "259           0.0         0.0     ...          0.0      0.0      0.0      0.0   \n",
      "597           0.0         0.0     ...          0.0      0.0      0.0      0.0   \n",
      "\n",
      "     Cabin_E  Cabin_F  Cabin_G  Embarked_C  Embarked_Q  Embarked_S  \n",
      "813      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "208      0.0      0.0      0.0         0.0         1.0         0.0  \n",
      "444      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "259      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "597      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#Finally we want to standard some of the columns: age and fare\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler() #This uses the distrobution of the data to calculate the new values\n",
    "\n",
    "to_transform = train[[\"Age\", \"Fare\"]]\n",
    "\n",
    "to_transform = stdsc.fit_transform(to_transform)\n",
    "\n",
    "train[[\"Age\", \"Fare\"]] = pd.DataFrame(to_transform)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#Now we split the data\n",
    "\n",
    "train_train, train_test, y_train, y_test = train_test_split(train, y, test_size=0.4)\n",
    "\n",
    "\n",
    "print train_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854341736695\n",
      "[0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1\n",
      " 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Alright, that didn't work let's go right to the PCA/LDA class\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "lda = LDA(n_components=20)\n",
    "\n",
    "train_data_lda = lda.fit_transform(train_train, y_train)\n",
    "train_data_pca = pca.fit_transform(train_train)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_train, y_train)\n",
    "\n",
    "print sum([lr.predict(train_test)[i]==y_test.values[i] for i in range(len(y_test.values))])/(len(y_test.values)*1.0)\n",
    "\n",
    "print y_test.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Name_Col.',\n",
      "       u'Name_Dr.', u'Name_Master.', u'Name_Miss.', u'Name_Mr.', u'Name_Mrs.',\n",
      "       u'Name_Ms.', u'Name_Rev.', u'Cabin_A', u'Cabin_B', u'Cabin_C',\n",
      "       u'Cabin_D', u'Cabin_E', u'Cabin_F', u'Cabin_G', u'Embarked_C',\n",
      "       u'Embarked_Q', u'Embarked_S'],\n",
      "      dtype='object')\n",
      "Index([u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Name_Col.',\n",
      "       u'Name_Dr.', u'Name_Master.', u'Name_Miss.', u'Name_Mr.', u'Name_Mrs.',\n",
      "       u'Name_Ms.', u'Name_Rev.', u'Cabin_A', u'Cabin_B', u'Cabin_C',\n",
      "       u'Cabin_D', u'Cabin_E', u'Cabin_F', u'Cabin_G', u'Embarked_C',\n",
      "       u'Embarked_Q', u'Embarked_S'],\n",
      "      dtype='object')\n",
      "[ 3.          0.         -1.82375021  4.          2.         -0.01870931\n",
      "  0.          0.          0.          1.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          1.        ]\n",
      "[0]\n",
      "[ 3.          1.          0.3349926   0.          0.         -0.49840706\n",
      "  0.          0.          0.          0.          1.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.        ]\n",
      "PassengerId,Survived\n",
      "892,0\n",
      "893,1\n",
      "894,0\n",
      "895,0\n",
      "896,1\n",
      "897,0\n",
      "898,1\n",
      "899,0\n",
      "900,1\n",
      "901,0\n",
      "902,0\n",
      "903,0\n",
      "904,1\n",
      "905,0\n",
      "906,1\n",
      "907,1\n",
      "908,0\n",
      "909,0\n",
      "910,0\n",
      "911,1\n",
      "912,0\n",
      "913,1\n",
      "914,1\n",
      "915,0\n",
      "916,1\n",
      "917,0\n",
      "918,1\n",
      "919,0\n",
      "920,0\n",
      "921,0\n",
      "922,0\n",
      "923,0\n",
      "924,1\n",
      "925,1\n",
      "926,0\n",
      "927,0\n",
      "928,1\n",
      "929,1\n",
      "930,0\n",
      "931,0\n",
      "932,0\n",
      "933,1\n",
      "934,0\n",
      "935,1\n",
      "936,1\n",
      "937,0\n",
      "938,0\n",
      "939,0\n",
      "940,1\n",
      "941,1\n",
      "942,0\n",
      "943,0\n",
      "944,1\n",
      "945,1\n",
      "946,0\n",
      "947,0\n",
      "948,0\n",
      "949,0\n",
      "950,0\n",
      "951,1\n",
      "952,0\n",
      "953,0\n",
      "954,0\n",
      "955,1\n",
      "956,1\n",
      "957,1\n",
      "958,1\n",
      "959,0\n",
      "960,0\n",
      "961,1\n",
      "962,1\n",
      "963,0\n",
      "964,1\n",
      "965,1\n",
      "966,1\n",
      "967,1\n",
      "968,0\n",
      "969,1\n",
      "970,0\n",
      "971,1\n",
      "972,1\n",
      "973,0\n",
      "974,0\n",
      "975,0\n",
      "976,0\n",
      "977,0\n",
      "978,1\n",
      "979,1\n",
      "980,1\n",
      "981,1\n",
      "982,1\n",
      "983,0\n",
      "984,1\n",
      "985,0\n",
      "986,0\n",
      "987,0\n",
      "988,1\n",
      "989,0\n",
      "990,1\n",
      "991,0\n",
      "992,1\n",
      "993,0\n",
      "994,0\n",
      "995,0\n",
      "996,1\n",
      "997,0\n",
      "998,0\n",
      "999,0\n",
      "1000,0\n",
      "1001,0\n",
      "1002,0\n",
      "1003,1\n",
      "1004,1\n",
      "1005,1\n",
      "1006,1\n",
      "1007,0\n",
      "1008,0\n",
      "1009,0\n",
      "1010,0\n",
      "1011,1\n",
      "1012,1\n",
      "1013,0\n",
      "1014,1\n",
      "1015,0\n",
      "1016,0\n",
      "1017,1\n",
      "1018,0\n",
      "1019,0\n",
      "1020,0\n",
      "1021,0\n",
      "1022,0\n",
      "1023,1\n",
      "1024,1\n",
      "1025,0\n",
      "1026,0\n",
      "1027,0\n",
      "1028,0\n",
      "1029,0\n",
      "1030,1\n",
      "1031,0\n",
      "1032,0\n",
      "1033,1\n",
      "1034,0\n",
      "1035,0\n",
      "1036,0\n",
      "1037,0\n",
      "1038,1\n",
      "1039,0\n",
      "1040,0\n",
      "1041,0\n",
      "1042,1\n",
      "1043,0\n",
      "1044,0\n",
      "1045,1\n",
      "1046,0\n",
      "1047,0\n",
      "1048,1\n",
      "1049,1\n",
      "1050,1\n",
      "1051,1\n",
      "1052,1\n",
      "1053,1\n",
      "1054,1\n",
      "1055,0\n",
      "1056,0\n",
      "1057,1\n",
      "1058,0\n",
      "1059,0\n",
      "1060,1\n",
      "1061,1\n",
      "1062,0\n",
      "1063,0\n",
      "1064,0\n",
      "1065,0\n",
      "1066,0\n",
      "1067,1\n",
      "1068,1\n",
      "1069,0\n",
      "1070,1\n",
      "1071,1\n",
      "1072,0\n",
      "1073,1\n",
      "1074,1\n",
      "1075,0\n",
      "1076,1\n",
      "1077,0\n",
      "1078,1\n",
      "1079,0\n",
      "1080,0\n",
      "1081,0\n",
      "1082,0\n",
      "1083,0\n",
      "1084,1\n",
      "1085,0\n",
      "1086,1\n",
      "1087,0\n",
      "1088,1\n",
      "1089,1\n",
      "1090,0\n",
      "1091,1\n",
      "1092,1\n",
      "1093,1\n",
      "1094,1\n",
      "1095,1\n",
      "1096,0\n",
      "1097,0\n",
      "1098,1\n",
      "1099,0\n",
      "1100,1\n",
      "1101,0\n",
      "1102,0\n",
      "1103,0\n",
      "1104,0\n",
      "1105,1\n",
      "1106,0\n",
      "1107,0\n",
      "1108,1\n",
      "1109,0\n",
      "1110,1\n",
      "1111,0\n",
      "1112,1\n",
      "1113,0\n",
      "1114,1\n",
      "1115,0\n",
      "1116,1\n",
      "1117,1\n",
      "1118,0\n",
      "1119,1\n",
      "1120,0\n",
      "1121,0\n",
      "1122,0\n",
      "1123,1\n",
      "1124,0\n",
      "1125,0\n",
      "1126,0\n",
      "1127,0\n",
      "1128,0\n",
      "1129,0\n",
      "1130,1\n",
      "1131,1\n",
      "1132,1\n",
      "1133,1\n",
      "1134,1\n",
      "1135,0\n",
      "1136,0\n",
      "1137,0\n",
      "1138,1\n",
      "1139,0\n",
      "1140,1\n",
      "1141,1\n",
      "1142,1\n",
      "1143,0\n",
      "1144,0\n",
      "1145,0\n",
      "1146,0\n",
      "1147,0\n",
      "1148,0\n",
      "1149,0\n",
      "1150,1\n",
      "1151,0\n",
      "1152,0\n",
      "1153,0\n",
      "1154,1\n",
      "1155,1\n",
      "1156,0\n",
      "1157,0\n",
      "1158,0\n",
      "1159,0\n",
      "1160,1\n",
      "1161,0\n",
      "1162,0\n",
      "1163,0\n",
      "1164,1\n",
      "1165,0\n",
      "1166,0\n",
      "1167,1\n",
      "1168,0\n",
      "1169,0\n",
      "1170,0\n",
      "1171,0\n",
      "1172,1\n",
      "1173,1\n",
      "1174,1\n",
      "1175,1\n",
      "1176,1\n",
      "1177,0\n",
      "1178,0\n",
      "1179,0\n",
      "1180,0\n",
      "1181,0\n",
      "1182,0\n",
      "1183,1\n",
      "1184,0\n",
      "1185,0\n",
      "1186,0\n",
      "1187,0\n",
      "1188,1\n",
      "1189,0\n",
      "1190,0\n",
      "1191,0\n",
      "1192,0\n",
      "1193,0\n",
      "1194,0\n",
      "1195,0\n",
      "1196,1\n",
      "1197,1\n",
      "1198,0\n",
      "1199,1\n",
      "1200,0\n",
      "1201,1\n",
      "1202,0\n",
      "1203,0\n",
      "1204,0\n",
      "1205,1\n",
      "1206,1\n",
      "1207,1\n",
      "1208,0\n",
      "1209,0\n",
      "1210,0\n",
      "1211,0\n",
      "1212,0\n",
      "1213,0\n",
      "1214,0\n",
      "1215,0\n",
      "1216,1\n",
      "1217,0\n",
      "1218,1\n",
      "1219,0\n",
      "1220,0\n",
      "1221,0\n",
      "1222,1\n",
      "1223,0\n",
      "1224,0\n",
      "1225,1\n",
      "1226,0\n",
      "1227,0\n",
      "1228,0\n",
      "1229,0\n",
      "1230,0\n",
      "1231,1\n",
      "1232,0\n",
      "1233,0\n",
      "1234,0\n",
      "1235,1\n",
      "1236,0\n",
      "1237,1\n",
      "1238,0\n",
      "1239,1\n",
      "1240,0\n",
      "1241,1\n",
      "1242,1\n",
      "1243,0\n",
      "1244,0\n",
      "1245,0\n",
      "1246,1\n",
      "1247,0\n",
      "1248,1\n",
      "1249,0\n",
      "1250,0\n",
      "1251,1\n",
      "1252,0\n",
      "1253,1\n",
      "1254,1\n",
      "1255,0\n",
      "1256,1\n",
      "1257,0\n",
      "1258,0\n",
      "1259,1\n",
      "1260,1\n",
      "1261,0\n",
      "1262,0\n",
      "1263,1\n",
      "1264,0\n",
      "1265,0\n",
      "1266,1\n",
      "1267,1\n",
      "1268,0\n",
      "1269,0\n",
      "1270,0\n",
      "1271,0\n",
      "1272,0\n",
      "1273,0\n",
      "1274,1\n",
      "1275,1\n",
      "1276,0\n",
      "1277,1\n",
      "1278,0\n",
      "1279,0\n",
      "1280,0\n",
      "1281,0\n",
      "1282,0\n",
      "1283,1\n",
      "1284,1\n",
      "1285,0\n",
      "1286,0\n",
      "1287,1\n",
      "1288,0\n",
      "1289,1\n",
      "1290,0\n",
      "1291,0\n",
      "1292,1\n",
      "1293,0\n",
      "1294,1\n",
      "1295,0\n",
      "1296,0\n",
      "1297,1\n",
      "1298,0\n",
      "1299,0\n",
      "1300,1\n",
      "1301,1\n",
      "1302,1\n",
      "1303,1\n",
      "1304,1\n",
      "1305,0\n",
      "1306,1\n",
      "1307,0\n",
      "1308,0\n",
      "1309,0\n"
     ]
    }
   ],
   "source": [
    "real_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "def prepare_data(train):\n",
    "    def process_name(name):\n",
    "        temp_name = name.split(',')[1].split()[0]\n",
    "        if temp_name in ['Miss.', 'Rev.', 'Dona.', 'Mrs.', 'Col.', 'Ms.', 'Mr.', 'Dr.', 'Master.']:\n",
    "            return temp_name\n",
    "        return \"NaN\"\n",
    "    #return name.split(',')[1].split()[0] # Just the prefix, Mr. Mrs. etc.\n",
    "\n",
    "    def process_cabin(cabin):\n",
    "        if type(cabin) is float:\n",
    "            return cabin\n",
    "        return cabin[0]\n",
    "    train = train.drop(\"Ticket\", 1)\n",
    "\n",
    "    train[\"Name\"] = train[\"Name\"].apply(process_name)\n",
    "    train[\"Cabin\"] = train[\"Cabin\"].apply(process_cabin)\n",
    "    \n",
    "    sex_le = LabelEncoder()\n",
    "    train[\"Sex\"] = sex_le.fit_transform(train[\"Sex\"].values)\n",
    "    \n",
    "    \n",
    "    cols_to_transform = [\"Name\", \"Cabin\", \"Embarked\"]\n",
    "    train = pd.get_dummies(train, prefix=cols_to_transform)\n",
    "    \n",
    "    imr = Imputer(missing_values=\"NaN\", strategy=\"mean\", axis=0)\n",
    "    col_names = train.columns #Array of the column headers\n",
    "\n",
    "    imr.fit(train)\n",
    "    imputed_train = imr.transform(train.values)\n",
    "    train = pd.DataFrame(imputed_train)\n",
    "    train.columns = col_names\n",
    "    \n",
    "    stdsc = StandardScaler() #This uses the distrobution of the data to calculate the new values\n",
    "    to_transform = train[[\"Age\", \"Fare\"]]\n",
    "    to_transform = stdsc.fit_transform(to_transform)\n",
    "    train[[\"Age\", \"Fare\"]] = pd.DataFrame(to_transform)\n",
    "    return train\n",
    "    \n",
    "real_test = prepare_data(real_test)\n",
    "real_test = real_test.drop([\"Name_Dona.\", \"PassengerId\"], 1) #Not in the training data\n",
    "\n",
    "print real_test.columns\n",
    "print train_train.columns\n",
    "\n",
    "print train_train.values[0]\n",
    "print lr.predict([train_train.values[0]])\n",
    "\n",
    "print real_test.values[0]\n",
    "\n",
    "print \"PassengerId,Survived\"\n",
    "for index, i in enumerate(lr.predict(real_test)):\n",
    "    print str(index+892) + \",\" + str(i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
