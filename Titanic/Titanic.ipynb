{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived  Pclass  \\\n",
      "PassengerId                     \n",
      "1                   0       3   \n",
      "2                   1       1   \n",
      "3                   1       3   \n",
      "4                   1       1   \n",
      "5                   0       3   \n",
      "\n",
      "                                                          Name     Sex   Age  \\\n",
      "PassengerId                                                                    \n",
      "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
      "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
      "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
      "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
      "5                                     Allen, Mr. William Henry    male  35.0   \n",
      "\n",
      "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "PassengerId                                                          \n",
      "1                1      0         A/5 21171   7.2500   NaN        S  \n",
      "2                1      0          PC 17599  71.2833   C85        C  \n",
      "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4                1      0            113803  53.1000  C123        S  \n",
      "5                0      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "\n",
    "y = train[\"Survived\"] #Answer vector\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miss.', 'Rev.', 'NaN', 'Mrs.', 'Col.', 'Ms.', 'Mr.', 'Dr.', 'Master.']\n",
      "             Survived  Pclass   Name     Sex   Age  SibSp  Parch     Fare  \\\n",
      "PassengerId                                                                 \n",
      "1                   0       3    Mr.    male  22.0      1      0   7.2500   \n",
      "2                   1       1   Mrs.  female  38.0      1      0  71.2833   \n",
      "3                   1       3  Miss.  female  26.0      0      0   7.9250   \n",
      "4                   1       1   Mrs.  female  35.0      1      0  53.1000   \n",
      "5                   0       3    Mr.    male  35.0      0      0   8.0500   \n",
      "\n",
      "            Cabin Embarked  \n",
      "PassengerId                 \n",
      "1             NaN        S  \n",
      "2               C        C  \n",
      "3             NaN        S  \n",
      "4               C        S  \n",
      "5             NaN        S  \n"
     ]
    }
   ],
   "source": [
    "def process_name(name):\n",
    "    temp_name = name.split(',')[1].split()[0]\n",
    "    if temp_name in ['Miss.', 'Rev.', 'Dona.', 'Mrs.', 'Col.', 'Ms.', 'Mr.', 'Dr.', 'Master.']:\n",
    "        return temp_name\n",
    "    return \"NaN\"\n",
    "    #return name.split(',')[1].split()[0] # Just the prefix, Mr. Mrs. etc.\n",
    "\n",
    "def process_cabin(cabin):\n",
    "    if type(cabin) is float:\n",
    "        return cabin\n",
    "    return cabin[0] #We only want the letter, numbers don't matter\n",
    "train = train.drop(\"Ticket\", 1) # There's no method to the madness there, impossible to parse\n",
    "\n",
    "train[\"Name\"] = train[\"Name\"].apply(process_name)\n",
    "train[\"Cabin\"] = train[\"Cabin\"].apply(process_cabin)\n",
    "\n",
    "print list(set(list(train[\"Name\"]))) #Verify all the different names that pop up\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Name_Col.  \\\n",
      "PassengerId                                                                  \n",
      "1                   0       3    1  22.0      1      0   7.2500        0.0   \n",
      "2                   1       1    0  38.0      1      0  71.2833        0.0   \n",
      "3                   1       3    0  26.0      0      0   7.9250        0.0   \n",
      "4                   1       1    0  35.0      1      0  53.1000        0.0   \n",
      "5                   0       3    1  35.0      0      0   8.0500        0.0   \n",
      "\n",
      "             Name_Dr.  Name_Master.     ...      Cabin_B  Cabin_C  Cabin_D  \\\n",
      "PassengerId                             ...                                  \n",
      "1                 0.0           0.0     ...          0.0      0.0      0.0   \n",
      "2                 0.0           0.0     ...          0.0      1.0      0.0   \n",
      "3                 0.0           0.0     ...          0.0      0.0      0.0   \n",
      "4                 0.0           0.0     ...          0.0      1.0      0.0   \n",
      "5                 0.0           0.0     ...          0.0      0.0      0.0   \n",
      "\n",
      "             Cabin_E  Cabin_F  Cabin_G  Cabin_T  Embarked_C  Embarked_Q  \\\n",
      "PassengerId                                                               \n",
      "1                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "2                0.0      0.0      0.0      0.0         1.0         0.0   \n",
      "3                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "4                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "5                0.0      0.0      0.0      0.0         0.0         0.0   \n",
      "\n",
      "             Embarked_S  \n",
      "PassengerId              \n",
      "1                   1.0  \n",
      "2                   0.0  \n",
      "3                   1.0  \n",
      "4                   1.0  \n",
      "5                   1.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "#Next step is converting everything that isn't NaN to an integer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sex_le = LabelEncoder()\n",
    "train[\"Sex\"] = sex_le.fit_transform(train[\"Sex\"].values) #This works good for something binary, but not cabin/embarked\n",
    "\n",
    "cols_to_transform = [\"Name\", \"Cabin\", \"Embarked\"]\n",
    "train = pd.get_dummies(train, prefix=cols_to_transform)\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.     3.     1.    22.     1.     0.     7.25   0.     0.     0.     0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     1.  ]\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Name_Col.  Name_Dr.  \\\n",
      "0       0.0     3.0  1.0  22.0    1.0    0.0   7.2500        0.0       0.0   \n",
      "1       1.0     1.0  0.0  38.0    1.0    0.0  71.2833        0.0       0.0   \n",
      "2       1.0     3.0  0.0  26.0    0.0    0.0   7.9250        0.0       0.0   \n",
      "3       1.0     1.0  0.0  35.0    1.0    0.0  53.1000        0.0       0.0   \n",
      "4       0.0     3.0  1.0  35.0    0.0    0.0   8.0500        0.0       0.0   \n",
      "\n",
      "   Name_Master.     ...      Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  \\\n",
      "0           0.0     ...          0.0      0.0      0.0      0.0      0.0   \n",
      "1           0.0     ...          0.0      0.0      1.0      0.0      0.0   \n",
      "2           0.0     ...          0.0      0.0      0.0      0.0      0.0   \n",
      "3           0.0     ...          0.0      0.0      1.0      0.0      0.0   \n",
      "4           0.0     ...          0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "   Cabin_F  Cabin_G  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0      0.0      0.0         0.0         0.0         1.0  \n",
      "1      0.0      0.0         1.0         0.0         0.0  \n",
      "2      0.0      0.0         0.0         0.0         1.0  \n",
      "3      0.0      0.0         0.0         0.0         1.0  \n",
      "4      0.0      0.0         0.0         0.0         1.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Index([u'Survived', u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare',\n",
      "       u'Name_Col.', u'Name_Dr.', u'Name_Master.', u'Name_Miss.', u'Name_Mr.',\n",
      "       u'Name_Mrs.', u'Name_Ms.', u'Name_Rev.', u'Cabin_A', u'Cabin_B',\n",
      "       u'Cabin_C', u'Cabin_D', u'Cabin_E', u'Cabin_F', u'Cabin_G',\n",
      "       u'Embarked_C', u'Embarked_Q', u'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Next we remove everything that is NaN\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values=\"NaN\", strategy=\"mean\", axis=0)\n",
    "\n",
    "col_names = train.columns #Array of the column headers\n",
    "\n",
    "imr.fit(train)\n",
    "imputed_train = imr.transform(train.values)\n",
    "print imputed_train[0]\n",
    "train = pd.DataFrame(imputed_train)\n",
    "train.columns = col_names\n",
    "train = train.drop([\"Name_NaN\", \"Cabin_T\"], 1) # Not in the test dataset\n",
    "print train.head()\n",
    "print train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Name_Col.  \\\n",
      "728       0.0     2.0  1.0 -0.361618    1.0    0.0 -0.124920        0.0   \n",
      "238       0.0     2.0  1.0 -0.823344    0.0    0.0 -0.437007        0.0   \n",
      "871       1.0     1.0  0.0  1.331378    1.0    1.0  0.409741        0.0   \n",
      "368       1.0     3.0  0.0  0.000000    0.0    0.0 -0.492378        0.0   \n",
      "630       1.0     1.0  1.0  3.870872    0.0    0.0 -0.044381        0.0   \n",
      "\n",
      "     Name_Dr.  Name_Master.     ...      Cabin_A  Cabin_B  Cabin_C  Cabin_D  \\\n",
      "728       0.0           0.0     ...          0.0      0.0      0.0      0.0   \n",
      "238       0.0           0.0     ...          0.0      0.0      0.0      0.0   \n",
      "871       0.0           0.0     ...          0.0      0.0      0.0      1.0   \n",
      "368       0.0           0.0     ...          0.0      0.0      0.0      0.0   \n",
      "630       0.0           0.0     ...          1.0      0.0      0.0      0.0   \n",
      "\n",
      "     Cabin_E  Cabin_F  Cabin_G  Embarked_C  Embarked_Q  Embarked_S  \n",
      "728      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "238      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "871      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "368      0.0      0.0      0.0         0.0         1.0         0.0  \n",
      "630      0.0      0.0      0.0         0.0         0.0         1.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#Finally we want to standard some of the columns: age and fare\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler() #This uses the distrobution of the data to calculate the new values\n",
    "\n",
    "to_transform = train[[\"Age\", \"Fare\"]]\n",
    "\n",
    "to_transform = stdsc.fit_transform(to_transform)\n",
    "\n",
    "train[[\"Age\", \"Fare\"]] = pd.DataFrame(to_transform)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#Now we split the data\n",
    "\n",
    "train_train, train_test, y_train, y_test = train_test_split(train, y, test_size=0.4)\n",
    "\n",
    "\n",
    "print train_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1\n",
      " 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#Alright, that didn't work let's go right to the PCA/LDA class\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "lda = LDA(n_components=8)\n",
    "\n",
    "train_data_lda = lda.fit_transform(train_train, y_train)\n",
    "train_data_pca = pca.fit_transform(train_train)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_train, y_train)\n",
    "\n",
    "print sum([lr.predict(train_test)[i]==y_test.values[i] for i in range(len(y_test.values))])/(len(y_test.values)*1.0)\n",
    "\n",
    "print y_test.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PassengerId', u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare',\n",
      "       u'Name_Col.', u'Name_Dr.', u'Name_Master.', u'Name_Miss.', u'Name_Mr.',\n",
      "       u'Name_Mrs.', u'Name_Ms.', u'Name_Rev.', u'Cabin_A', u'Cabin_B',\n",
      "       u'Cabin_C', u'Cabin_D', u'Cabin_E', u'Cabin_F', u'Cabin_G',\n",
      "       u'Embarked_C', u'Embarked_Q', u'Embarked_S'],\n",
      "      dtype='object')\n",
      "PassengerId,Survived\n",
      "892,1\n",
      "893,1\n",
      "894,1\n",
      "895,1\n",
      "896,1\n",
      "897,1\n",
      "898,1\n",
      "899,1\n",
      "900,1\n",
      "901,1\n",
      "902,1\n",
      "903,1\n",
      "904,1\n",
      "905,1\n",
      "906,1\n",
      "907,1\n",
      "908,1\n",
      "909,1\n",
      "910,1\n",
      "911,1\n",
      "912,1\n",
      "913,1\n",
      "914,1\n",
      "915,1\n",
      "916,1\n",
      "917,1\n",
      "918,1\n",
      "919,1\n",
      "920,1\n",
      "921,1\n",
      "922,1\n",
      "923,1\n",
      "924,1\n",
      "925,1\n",
      "926,1\n",
      "927,1\n",
      "928,1\n",
      "929,1\n",
      "930,1\n",
      "931,1\n",
      "932,1\n",
      "933,1\n",
      "934,1\n",
      "935,1\n",
      "936,1\n",
      "937,1\n",
      "938,1\n",
      "939,1\n",
      "940,1\n",
      "941,1\n",
      "942,1\n",
      "943,1\n",
      "944,1\n",
      "945,1\n",
      "946,1\n",
      "947,1\n",
      "948,1\n",
      "949,1\n",
      "950,1\n",
      "951,1\n",
      "952,1\n",
      "953,1\n",
      "954,1\n",
      "955,1\n",
      "956,1\n",
      "957,1\n",
      "958,1\n",
      "959,1\n",
      "960,1\n",
      "961,1\n",
      "962,1\n",
      "963,1\n",
      "964,1\n",
      "965,1\n",
      "966,1\n",
      "967,1\n",
      "968,1\n",
      "969,1\n",
      "970,1\n",
      "971,1\n",
      "972,1\n",
      "973,1\n",
      "974,1\n",
      "975,1\n",
      "976,1\n",
      "977,1\n",
      "978,1\n",
      "979,1\n",
      "980,1\n",
      "981,1\n",
      "982,1\n",
      "983,1\n",
      "984,1\n",
      "985,1\n",
      "986,1\n",
      "987,1\n",
      "988,1\n",
      "989,1\n",
      "990,1\n",
      "991,1\n",
      "992,1\n",
      "993,1\n",
      "994,1\n",
      "995,1\n",
      "996,1\n",
      "997,1\n",
      "998,1\n",
      "999,1\n",
      "1000,1\n",
      "1001,1\n",
      "1002,1\n",
      "1003,1\n",
      "1004,1\n",
      "1005,1\n",
      "1006,1\n",
      "1007,1\n",
      "1008,1\n",
      "1009,1\n",
      "1010,1\n",
      "1011,1\n",
      "1012,1\n",
      "1013,1\n",
      "1014,1\n",
      "1015,1\n",
      "1016,1\n",
      "1017,1\n",
      "1018,1\n",
      "1019,1\n",
      "1020,1\n",
      "1021,1\n",
      "1022,1\n",
      "1023,1\n",
      "1024,1\n",
      "1025,1\n",
      "1026,1\n",
      "1027,1\n",
      "1028,1\n",
      "1029,1\n",
      "1030,1\n",
      "1031,1\n",
      "1032,1\n",
      "1033,1\n",
      "1034,1\n",
      "1035,1\n",
      "1036,1\n",
      "1037,1\n",
      "1038,1\n",
      "1039,1\n",
      "1040,1\n",
      "1041,1\n",
      "1042,1\n",
      "1043,1\n",
      "1044,1\n",
      "1045,1\n",
      "1046,1\n",
      "1047,1\n",
      "1048,1\n",
      "1049,1\n",
      "1050,1\n",
      "1051,1\n",
      "1052,1\n",
      "1053,1\n",
      "1054,1\n",
      "1055,1\n",
      "1056,1\n",
      "1057,1\n",
      "1058,1\n",
      "1059,1\n",
      "1060,1\n",
      "1061,1\n",
      "1062,1\n",
      "1063,1\n",
      "1064,1\n",
      "1065,1\n",
      "1066,1\n",
      "1067,1\n",
      "1068,1\n",
      "1069,1\n",
      "1070,1\n",
      "1071,1\n",
      "1072,1\n",
      "1073,1\n",
      "1074,1\n",
      "1075,1\n",
      "1076,1\n",
      "1077,1\n",
      "1078,1\n",
      "1079,1\n",
      "1080,1\n",
      "1081,1\n",
      "1082,1\n",
      "1083,1\n",
      "1084,1\n",
      "1085,1\n",
      "1086,1\n",
      "1087,1\n",
      "1088,1\n",
      "1089,1\n",
      "1090,1\n",
      "1091,1\n",
      "1092,1\n",
      "1093,1\n",
      "1094,1\n",
      "1095,1\n",
      "1096,1\n",
      "1097,1\n",
      "1098,1\n",
      "1099,1\n",
      "1100,1\n",
      "1101,1\n",
      "1102,1\n",
      "1103,1\n",
      "1104,1\n",
      "1105,1\n",
      "1106,1\n",
      "1107,1\n",
      "1108,1\n",
      "1109,1\n",
      "1110,1\n",
      "1111,1\n",
      "1112,1\n",
      "1113,1\n",
      "1114,1\n",
      "1115,1\n",
      "1116,1\n",
      "1117,1\n",
      "1118,1\n",
      "1119,1\n",
      "1120,1\n",
      "1121,1\n",
      "1122,1\n",
      "1123,1\n",
      "1124,1\n",
      "1125,1\n",
      "1126,1\n",
      "1127,1\n",
      "1128,1\n",
      "1129,1\n",
      "1130,1\n",
      "1131,1\n",
      "1132,1\n",
      "1133,1\n",
      "1134,1\n",
      "1135,1\n",
      "1136,1\n",
      "1137,1\n",
      "1138,1\n",
      "1139,1\n",
      "1140,1\n",
      "1141,1\n",
      "1142,1\n",
      "1143,1\n",
      "1144,1\n",
      "1145,1\n",
      "1146,1\n",
      "1147,1\n",
      "1148,1\n",
      "1149,1\n",
      "1150,1\n",
      "1151,1\n",
      "1152,1\n",
      "1153,1\n",
      "1154,1\n",
      "1155,1\n",
      "1156,1\n",
      "1157,1\n",
      "1158,1\n",
      "1159,1\n",
      "1160,1\n",
      "1161,1\n",
      "1162,1\n",
      "1163,1\n",
      "1164,1\n",
      "1165,1\n",
      "1166,1\n",
      "1167,1\n",
      "1168,1\n",
      "1169,1\n",
      "1170,1\n",
      "1171,1\n",
      "1172,1\n",
      "1173,1\n",
      "1174,1\n",
      "1175,1\n",
      "1176,1\n",
      "1177,1\n",
      "1178,1\n",
      "1179,1\n",
      "1180,1\n",
      "1181,1\n",
      "1182,1\n",
      "1183,1\n",
      "1184,1\n",
      "1185,1\n",
      "1186,1\n",
      "1187,1\n",
      "1188,1\n",
      "1189,1\n",
      "1190,1\n",
      "1191,1\n",
      "1192,1\n",
      "1193,1\n",
      "1194,1\n",
      "1195,1\n",
      "1196,1\n",
      "1197,1\n",
      "1198,1\n",
      "1199,1\n",
      "1200,1\n",
      "1201,1\n",
      "1202,1\n",
      "1203,1\n",
      "1204,1\n",
      "1205,1\n",
      "1206,1\n",
      "1207,1\n",
      "1208,1\n",
      "1209,1\n",
      "1210,1\n",
      "1211,1\n",
      "1212,1\n",
      "1213,1\n",
      "1214,1\n",
      "1215,1\n",
      "1216,1\n",
      "1217,1\n",
      "1218,1\n",
      "1219,1\n",
      "1220,1\n",
      "1221,1\n",
      "1222,1\n",
      "1223,1\n",
      "1224,1\n",
      "1225,1\n",
      "1226,1\n",
      "1227,1\n",
      "1228,1\n",
      "1229,1\n",
      "1230,1\n",
      "1231,1\n",
      "1232,1\n",
      "1233,1\n",
      "1234,1\n",
      "1235,1\n",
      "1236,1\n",
      "1237,1\n",
      "1238,1\n",
      "1239,1\n",
      "1240,1\n",
      "1241,1\n",
      "1242,1\n",
      "1243,1\n",
      "1244,1\n",
      "1245,1\n",
      "1246,1\n",
      "1247,1\n",
      "1248,1\n",
      "1249,1\n",
      "1250,1\n",
      "1251,1\n",
      "1252,1\n",
      "1253,1\n",
      "1254,1\n",
      "1255,1\n",
      "1256,1\n",
      "1257,1\n",
      "1258,1\n",
      "1259,1\n",
      "1260,1\n",
      "1261,1\n",
      "1262,1\n",
      "1263,1\n",
      "1264,1\n",
      "1265,1\n",
      "1266,1\n",
      "1267,1\n",
      "1268,1\n",
      "1269,1\n",
      "1270,1\n",
      "1271,1\n",
      "1272,1\n",
      "1273,1\n",
      "1274,1\n",
      "1275,1\n",
      "1276,1\n",
      "1277,1\n",
      "1278,1\n",
      "1279,1\n",
      "1280,1\n",
      "1281,1\n",
      "1282,1\n",
      "1283,1\n",
      "1284,1\n",
      "1285,1\n",
      "1286,1\n",
      "1287,1\n",
      "1288,1\n",
      "1289,1\n",
      "1290,1\n",
      "1291,1\n",
      "1292,1\n",
      "1293,1\n",
      "1294,1\n",
      "1295,1\n",
      "1296,1\n",
      "1297,1\n",
      "1298,1\n",
      "1299,1\n",
      "1300,1\n",
      "1301,1\n",
      "1302,1\n",
      "1303,1\n",
      "1304,1\n",
      "1305,1\n",
      "1306,1\n",
      "1307,1\n",
      "1308,1\n",
      "1309,1\n"
     ]
    }
   ],
   "source": [
    "real_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "def prepare_data(train):\n",
    "    def process_name(name):\n",
    "        temp_name = name.split(',')[1].split()[0]\n",
    "        if temp_name in ['Miss.', 'Rev.', 'Dona.', 'Mrs.', 'Col.', 'Ms.', 'Mr.', 'Dr.', 'Master.']:\n",
    "            return temp_name\n",
    "        return \"NaN\"\n",
    "    #return name.split(',')[1].split()[0] # Just the prefix, Mr. Mrs. etc.\n",
    "\n",
    "    def process_cabin(cabin):\n",
    "        if type(cabin) is float:\n",
    "            return cabin\n",
    "        return cabin[0]\n",
    "    train = train.drop(\"Ticket\", 1)\n",
    "\n",
    "    train[\"Name\"] = train[\"Name\"].apply(process_name)\n",
    "    train[\"Cabin\"] = train[\"Cabin\"].apply(process_cabin)\n",
    "    \n",
    "    sex_le = LabelEncoder()\n",
    "    train[\"Sex\"] = sex_le.fit_transform(train[\"Sex\"].values)\n",
    "    \n",
    "    \n",
    "    cols_to_transform = [\"Name\", \"Cabin\", \"Embarked\"]\n",
    "    train = pd.get_dummies(train, prefix=cols_to_transform)\n",
    "    \n",
    "    imr = Imputer(missing_values=\"NaN\", strategy=\"mean\", axis=0)\n",
    "    col_names = train.columns #Array of the column headers\n",
    "\n",
    "    imr.fit(train)\n",
    "    imputed_train = imr.transform(train.values)\n",
    "    train = pd.DataFrame(imputed_train)\n",
    "    train.columns = col_names\n",
    "    \n",
    "    stdsc = StandardScaler() #This uses the distrobution of the data to calculate the new values\n",
    "    to_transform = train[[\"Age\", \"Fare\"]]\n",
    "    to_transform = stdsc.fit_transform(to_transform)\n",
    "    train[[\"Age\", \"Fare\"]] = pd.DataFrame(to_transform)\n",
    "    return train\n",
    "    \n",
    "real_test = prepare_data(real_test)\n",
    "real_test = real_test.drop([\"Name_Dona.\"], 1) #Not in the training data\n",
    "\n",
    "print real_test.columns\n",
    "\n",
    "print \"PassengerId,Survived\"\n",
    "for index, i in enumerate(lr.predict(real_test)):\n",
    "    print str(int(real_test.values[index][0])) + \",\" + str(i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
